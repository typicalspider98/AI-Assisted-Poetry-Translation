import os
import json
import pickle
import re
import ahocorasick  # pip install pyahocorasick
import gradio as gr

# === è¯é¢„å¤„ç†
def normalize_text_for_matching(text: str) -> str:
    text = text.lower()
    text = re.sub(r"\b(\w+)[â€™']s\b", r"\1", text)
    text = re.sub(r"[^\w\s]", "", text)
    return text

# === åŠ è½½ JSON è¯å…¸ä¸»è¯æ¡
def get_words_from_json(json_folder="nz_dictionary_jsons"):
    all_words = set()
    for file in os.listdir(json_folder):
        if file.endswith(".json"):
            with open(os.path.join(json_folder, file), "r", encoding="utf-8") as f:
                data = json.load(f)
                for entry in data:
                    word = entry.get("word", "").strip().lower()
                    if len(word) >= 3 and word.isalpha():
                        all_words.add(word)
    return all_words

# === é»‘åå•åŠ è½½
def load_blacklist(filepath="low_value_words.txt"):
    if not os.path.exists(filepath):
        return set()
    with open(filepath, "r", encoding="utf-8") as f:
        return {line.strip().lower() for line in f if line.strip()}

# === æ„å»ºä¸åŠ è½½è‡ªåŠ¨æœº
def build_and_save_ac_automaton(json_folder="nz_dictionary_jsons", output_path="ac_nzdict.pkl"):
    phrases = get_words_from_json(json_folder)
    A = ahocorasick.Automaton()
    for phrase in phrases:
        A.add_word(phrase, phrase)
    A.make_automaton()
    with open(output_path, "wb") as f:
        pickle.dump(A, f)

def load_ac_automaton(pkl_path="ac_nzdict.pkl"):
    with open(pkl_path, "rb") as f:
        A = pickle.load(f)
    return A

# === ä¸»åŒ¹é…å‡½æ•°
def match_nz_phrases(text: str, automaton, blacklist=None) -> list:
    cleaned = normalize_text_for_matching(text)
    hits = set()
    for _, phrase in automaton.iter(cleaned):
        if re.search(rf"\b{re.escape(phrase)}\b", cleaned):
            hits.add(phrase)
    if blacklist:
        hits = {w for w in hits if w not in blacklist}
    return sorted(hits)

# === åŠ è½½é˜¶æ®µ
PKL_PATH = "ac_nzdict.pkl"
JSON_FOLDER = "nz_dictionary_jsons"
BLACKLIST_PATH = "low_value_words.txt"

if not os.path.exists(PKL_PATH):
    print("ğŸ”§ æ„å»ºè‡ªåŠ¨æœºä¸­...")
    build_and_save_ac_automaton(JSON_FOLDER, PKL_PATH)
AC_MACHINE = load_ac_automaton(PKL_PATH)
BLACKLIST = load_blacklist(BLACKLIST_PATH)

# === Gradio æ¥å£
def analyze_single_translation(text: str):
    filtered_hits = match_nz_phrases(text, AC_MACHINE, BLACKLIST)
    return f"ğŸ” å‘½ä¸­æœ‰æ•ˆè¯æ¡æ•°ï¼š{len(filtered_hits)}\nâœ… æœ‰æ•ˆè¯æ¡ï¼š{filtered_hits}"

with gr.Blocks() as demo:
    gr.Markdown("## ğŸ§  æ–°è¥¿å…°è¯æ¡å‘½ä¸­æ£€æµ‹å·¥å…·ï¼ˆGradioç‰ˆï¼‰")
    gr.Markdown("è¯·è¾“å…¥å®Œæ•´ç¿»è¯‘æ–‡æœ¬ï¼ˆæ•´é¦–è¯—ï¼‰ï¼š")
    input_box = gr.Textbox(lines=10, label="è¾“å…¥ç¿»è¯‘æ–‡æœ¬")
    output_box = gr.Textbox(lines=6, label="å‘½ä¸­ç»“æœ", interactive=False)
    analyze_button = gr.Button("åˆ†æå‘½ä¸­è¯")

    analyze_button.click(fn=analyze_single_translation, inputs=input_box, outputs=output_box)

demo.launch(server_name="0.0.0.0", server_port=7860, share=False)
