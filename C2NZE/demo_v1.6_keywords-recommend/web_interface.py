import gradio as gr
import translation_logic
import semantic_helper
import json

try:
    import tkinter as tk
    from tkinter import filedialog
    USE_TKINTER = True
except ImportError:
    USE_TKINTER = False

from gradio_checkboxgroupmarkdown import CheckboxGroupMarkdown

def select_model_folder():
    if USE_TKINTER:
        root = tk.Tk()
        root.withdraw()
        folder_selected = filedialog.askdirectory()
        return folder_selected if folder_selected else "æœªé€‰æ‹©æ–‡ä»¶å¤¹ | No folder selected"
    return "è¯·æ‰‹åŠ¨è¾“å…¥æ¨¡å‹è·¯å¾„ | Please enter the model path manually"

with gr.Blocks() as demo:
    gr.Markdown("## ä¸­æ–‡å¤è¯—ç¿»è¯‘ï¼ˆQwen + DeepSeek å¤šè½®äº¤äº’ç¤ºä¾‹ï¼‰ | Chinese ancient poetry translation (Qwen + DeepSeek multi-round interaction example)")

    # ==== è¾“å…¥åŒºåŸŸ ====
    with gr.Row():
        with gr.Column(scale=2):
            input_poetry = gr.Textbox(label="è¯—æ­Œè¾“å…¥ | Poetry Input", lines=6, value="ã€Šé™å¤œæ€ã€‹\nåºŠå‰æ˜æœˆå…‰ï¼Œç–‘æ˜¯åœ°ä¸Šéœœã€‚ä¸¾å¤´æœ›æ˜æœˆï¼Œä½å¤´æ€æ•…ä¹¡ã€‚")
            btn_get_instruction = gr.Button("ç”Ÿæˆåˆå§‹æç¤ºæ–‡æœ¬ | Generate initial prompt text")
            btn_get_instruction_EN = gr.Button("ç”ŸæˆENåˆå§‹æç¤ºæ–‡æœ¬ | Generate initial english prompt text")
        with gr.Column(scale=6):
            textbox_instruction = gr.Textbox(label="ç¿»è¯‘æç¤ºæ–‡æœ¬ï¼ˆå¯ç¼–è¾‘ï¼‰ | Translation hint text (editable)", lines=8)

    with gr.Row():
        with gr.Column(scale=4):
            model_path_display = gr.Textbox(label="å½“å‰æ¨¡å‹è·¯å¾„ | Current model path", interactive=True, value="/workspace/AI-Assisted-Poetry-Translation/C2NZE/models/DeepSeek-R1-Distill-Qwen-14B")
        with gr.Column(scale=2):
            btn_select_model = gr.Button("é€‰æ‹©æ¨¡å‹æ–‡ä»¶å¤¹ | Select Model Folder")
            btn_set_model_path = gr.Button("ç¡®è®¤æ¨¡å‹è·¯å¾„ | Confirm the model path")
        with gr.Column(scale=4):
            model_path_status = gr.Textbox(label="æ¨¡å‹è·¯å¾„çŠ¶æ€ | Model Path Status", interactive=False)

    with gr.Row():
        with gr.Column(scale=1):
            model_token_input = gr.Textbox(label="æ¨¡å‹Tokenä¸Šé™ | The upper limit of the model token length", value="2048")
            btn_set_model_token = gr.Button("è®¾ç½®Token | Set Token")
            model_token_status = gr.Textbox(label="Tokenè®¾ç½®ç»“æœ | Token setting results", interactive=False)
            
        with gr.Column(scale=8):
            btn_submit_boss_model = gr.Button("æäº¤åˆ°æœ¬åœ°Bossæ¨¡å‹ | Submit to local Boss model")
            textbox_prompt0 = gr.Textbox(label="Bossç”Ÿæˆçš„Prompt0 | Boss spawned Prompt0", lines=10)

    # ==== å…³é”®è¯åŒºåŸŸ ====
    with gr.Row():
        with gr.Column(scale=2):
            btn_gen_prompt_keywords = gr.Button("ç”Ÿæˆå…³é”®è¯æå–æç¤ºè¯ | Generate keyword extraction prompt words")
            btn_gen_prompt_keywords_EN = gr.Button("ç”ŸæˆENå…³é”®è¯æå–æç¤ºè¯ | Generate keyword extraction english prompt words")
            keyword_token_limit = gr.Textbox(label="å…³é”®è¯æç¤º Token ä¸Šé™ | The upper limit of the token length used for keyword generation", value="2048")
            btn_get_keywords = gr.Button("æå–å…³é”®è¯ | Extract keywords")
        with gr.Column(scale=8):
            textbox_prompt_keywords = gr.Textbox(label="å…³é”®è¯æç¤ºè¯ | Keyword prompts", lines=8)

    with gr.Row():
        with gr.Column(scale=4):
            textbox_keywords_json = gr.Textbox(label="å…³é”®è¯ JSON | Keywords JSON", lines=4)
        with gr.Column(scale=2):
            btn_query_redis = gr.Button("æŸ¥è¯¢å‘é‡æ•°æ®åº“ï¼ˆTopKï¼‰ | Query vector database (TopK)", scale=4)
            query_status = gr.Textbox(label="çŠ¶æ€æç¤º | Status of the query", interactive=False, scale=1)

    # ==== æŸ¥è¯¢ & åˆ†ç»„å±•ç¤ºåŒº ====
    # with gr.Row():
        # btn_query_redis = gr.Button("æŸ¥è¯¢å‘é‡æ•°æ®åº“ï¼ˆTopKï¼‰ | Query vector database (TopK)", scale=4)
        # query_status = gr.Textbox(label="çŠ¶æ€æç¤º | Status of the query", interactive=False, scale=1)
    # btn_query_redis = gr.Button("æŸ¥è¯¢å‘é‡æ•°æ®åº“ï¼ˆTopKï¼‰")
    # query_status = gr.Textbox(label="çŠ¶æ€æç¤º", interactive=False)
    all_related_data = gr.State([])

    # æœ€å¤šå±•ç¤º 50 ä¸ªå…³é”®è¯çš„ç›¸å…³è¯æ¨èï¼ˆé€ä¸ªå®šä¹‰å¹¶æ³¨å†Œç»„ä»¶ï¼‰
    checkbox_groups = []
    accordion_blocks = []

    grouped_checkboxes_display = gr.Column()

    for i in range(50):
        acc = gr.Accordion(f"å…³é”®è¯ç»„ {i+1} | Keyword group {i+1}", open=False, visible=False)
        with acc:
            with gr.Row():
                cb_left = CheckboxGroupMarkdown(choices=[], label=f"å…³é”®è¯{i+1} å·¦ä¾§ | Keyword {i+1} Left side", visible=True)
                cb_right = CheckboxGroupMarkdown(choices=[], label=f"å…³é”®è¯{i+1} å³ä¾§ | Keyword {i+1} Right side", visible=True)

            btn_close_title = gr.Button("â¬†ï¸ æ”¶èµ·æ­¤å…³é”®è¯ç»„ï¼ˆè¿”å›ä¸Šæ–¹ï¼‰ | Collapse this keyword group (return to top)", variant="secondary")
            btn_close_title.click(fn=lambda: gr.update(open=False), inputs=[], outputs=acc)

            btn_next = gr.Button("ğŸ”½ æŸ¥çœ‹ä¸‹ä¸€ä¸ªå…³é”®è¯ç»„ | View next keyword group", variant="secondary")
            def make_next_fn(index):
                def inner():
                    updates = [gr.update(open=False) if i == index else gr.update() for i in range(50)]
                    if index + 1 < 50:
                        updates[index + 1] = gr.update(open=True)
                    return updates
                return inner
            btn_next.click(fn=make_next_fn(i), inputs=[], outputs=accordion_blocks)

        checkbox_groups.append([cb_left, cb_right])
        accordion_blocks.append(acc)
        # checkbox_groups.append(cb)
        # accordion_blocks.append(acc)

    # ==== å‹¾é€‰ & æ³¨å…¥ ====
    btn_confirm_selection = gr.Button("ç¡®è®¤é€‰æ‹©å…³é”®è¯ä¸ç›¸å…³è¯ | Confirm the selection of keywords and related words")
    textbox_selected_summary = gr.Textbox(label="æœ€ç»ˆé€‰æ‹©ç»“æœï¼ˆå«è¯´æ˜å’Œä¾‹å¥ï¼‰ | Final selection results (including instructions and examples)", lines=12)

    btn_inject_keywords = gr.Button("æ³¨å…¥å…³é”®è¯ | Inject keywords")
    textbox_final_prompt = gr.Textbox(label="æ³¨å…¥åçš„æç¤ºè¯ | Prompt words after injection", lines=8, interactive=True)

    # ==== ç¿»è¯‘ + å®¡æŸ¥ ====
    btn_submit_prompt = gr.Button("æäº¤ Prompt0 ç»™ DeepSeek | Submit Prompt0 to DeepSeek")
    textbox_translation1 = gr.Textbox(label="DeepSeekè¿”å›çš„Translation1 | Translation1 returned by DeepSeek", lines=8, interactive=True)

    btn_call_ds_review = gr.Button("æäº¤ç¿»è¯‘å®¡æŸ¥ | Submit Translation Review")
    textbox_review = gr.Textbox(label="Qwenå®¡æŸ¥æ„è§ï¼ˆå¯ç¼–è¾‘ï¼‰ | Qwen review comments (editable)", lines=8, interactive=True)

    textbox_translation2 = gr.Textbox(label="DeepSeekè¿”å›çš„Translation2 | Translation2 returned by DeepSeek", lines=8)
    btn_submit_revision = gr.Button("ä¿®è®¢åæäº¤ç»™ DS | Submit to DS after revision")

    btn_loop_review = gr.Button("å†æ¬¡æäº¤å®¡æŸ¥ï¼ˆå¾ªç¯ï¼‰ | Submit for review again (loop)")

    # ==== åŠŸèƒ½ç»‘å®š ====
    btn_select_model.click(fn=select_model_folder, inputs=[], outputs=model_path_display)
    btn_set_model_path.click(fn=translation_logic.set_model_path, inputs=model_path_display, outputs=model_path_status)
    btn_set_model_token.click(fn=translation_logic.set_local_model_token, inputs=model_token_input, outputs=model_token_status)
    btn_get_instruction.click(fn=translation_logic.generate_instruction_text, inputs=input_poetry, outputs=textbox_instruction)
    btn_get_instruction_EN.click(fn=translation_logic.generate_instruction_text_EN, inputs=input_poetry, outputs=textbox_instruction)
    btn_submit_boss_model.click(fn=translation_logic.call_local_qwen_with_instruction, inputs=[textbox_instruction, model_token_input], outputs=textbox_prompt0)

    btn_submit_prompt.click(fn=translation_logic.call_deepseek_api, inputs=textbox_final_prompt, outputs=textbox_translation1)

    btn_call_ds_review.click(fn=translation_logic.review_translation_with_boss, inputs=[textbox_final_prompt, textbox_translation1], outputs=textbox_review)
    btn_submit_revision.click(fn=translation_logic.call_deepseek_api, inputs=textbox_final_prompt, outputs=textbox_translation2)
    btn_loop_review.click(fn=translation_logic.review_translation_with_boss, inputs=[textbox_final_prompt, textbox_translation2], outputs=textbox_review)

    btn_gen_prompt_keywords.click(
        fn=lambda poem, limit: semantic_helper.build_keyword_prompt(poem, int(limit)),
        inputs=[input_poetry, keyword_token_limit],
        outputs=textbox_prompt_keywords
    )
    btn_gen_prompt_keywords_EN.click(
        fn=lambda poem, limit: semantic_helper.build_keyword_prompt_EN(poem, int(limit)),
        inputs=[input_poetry, keyword_token_limit],
        outputs=textbox_prompt_keywords
    )

    btn_get_keywords.click(
        fn=lambda prompt_text, limit: semantic_helper.extract_keywords_with_llm(prompt_text, int(limit)),
        inputs=[textbox_prompt_keywords, keyword_token_limit],
        outputs=textbox_keywords_json
    )

    btn_query_redis.click(
        fn=lambda: "æ­£åœ¨æŸ¥è¯¢å‘é‡æ•°æ®åº“ä¸­ï¼Œè¯·ç¨å€™... | Querying the vector database, please wait...",
        inputs=[],
        outputs=query_status
    ).then(
        fn=semantic_helper.query_related_terms_from_redis,
        inputs=textbox_keywords_json,
        outputs=all_related_data
    ).then(
        fn=semantic_helper.render_checkbox_groups_by_keyword,
        inputs=all_related_data,
        outputs=[cb for pair in checkbox_groups for cb in pair]
    ).then(
        fn=lambda data: [gr.update(visible=i < len(data)) for i in range(50)],
        inputs=all_related_data,
        outputs=accordion_blocks
    ).then(
        fn=lambda: "âœ… æŸ¥è¯¢å®Œæˆï¼ | Query completed!",
        inputs=[],
        outputs=query_status
    )

    btn_confirm_selection.click(
        fn=semantic_helper.collect_grouped_markdown_selection,
        inputs=[cb for pair in checkbox_groups for cb in pair] + [all_related_data],
        outputs=textbox_selected_summary
    )

    btn_inject_keywords.click(
        fn=semantic_helper.inject_keywords_into_prompt,
        inputs=[textbox_prompt0, textbox_selected_summary],
        outputs=textbox_final_prompt
    )

    demo.launch(server_name="0.0.0.0", server_port=7860, share=True)
