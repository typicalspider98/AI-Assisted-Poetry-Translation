import requests
from bs4 import BeautifulSoup
import json

BASE_URL = "https://en.wiktionary.org"
CATEGORY_URL = "https://en.wiktionary.org/wiki/Category:New_Zealand_English"  # âœ… æ­£ç¡®é¡µé¢

def get_entry_links(max_links=5):
    response = requests.get(CATEGORY_URL)
    soup = BeautifulSoup(response.text, "html.parser")
    links = []

    # ä» mw-pages åŒºå—ä¸­æå–è¯æ¡é“¾æ¥
    for div in soup.select("div.mw-category-group"):
        for a in div.find_all("a"):
            title = a.get("title")
            href = a.get("href")
            if title and href and not title.startswith("Category:"):
                links.append((title, BASE_URL + href))
            if len(links) >= max_links:
                break
        if len(links) >= max_links:
            break

    print(f"ğŸ”— è·å–åˆ° {len(links)} ä¸ªè¯æ¡é“¾æ¥")
    return links

def extract_entry_data(title, url):
    print(f"ğŸ“¥ æ­£åœ¨æŠ“å–è¯æ¡: {title} => {url}")
    response = requests.get(url)
    soup = BeautifulSoup(response.text, "html.parser")

    entry = {
        "word": title,
        "pos": None,
        "definitions": []
    }

    # æ›´å¥å£®çš„æ–¹å¼å¯»æ‰¾ English åŒºå—
    h2_tags = soup.find_all("h2")
    english_section = None
    for h2 in h2_tags:
        if h2.get("id") == "English" or h2.find(id="English"):
            english_section = h2
            break

    if not english_section:
        print("âš ï¸ æ²¡æœ‰æ‰¾åˆ° English åŒºå—")
        return None

    tag = english_section.find_next_sibling()
    while tag:
        if tag.name == "h2":
            break  # åˆ°ä¸‹ä¸€ä¸ªè¯­è¨€éƒ¨åˆ†ï¼Œç»“æŸ
        if tag.name == "h3":
            span = tag.find("span", class_="mw-headline")
            if span:
                entry["pos"] = span.text.strip().lower()
                print(f"ğŸ” å‘ç°è¯æ€§: {entry['pos']}")
        if tag.name == "ol":
            for li in tag.find_all("li", recursive=False):
                # ç§»é™¤ usage æ ‡ç­¾
                for usage in li.select(".usage-label-sense"):
                    usage.extract()

                meaning = li.get_text(" ", strip=True)

                # æå–ä¾‹å¥
                examples = []
                for quote in li.select(".h-quotation"):
                    ex_text = quote.get_text(strip=True)
                    if ex_text:
                        examples.append(ex_text)

                entry["definitions"].append({
                    "meaning": meaning,
                    "examples": examples,
                    "region": "New Zealand",
                    "source": "Wiktionary"
                })
                print(f"âœ… æŠ“å–å®šä¹‰: {meaning[:60]}...")
        tag = tag.find_next_sibling()

    if not entry["definitions"]:
        print("âš ï¸ æ²¡æœ‰æ‰¾åˆ° definitions")
    return entry if entry["definitions"] else None

# è°ƒè¯•è¿è¡Œï¼šæŠ“å–å‰ 5 ä¸ªè¯æ¡åŠå®šä¹‰
sample_links = get_entry_links(5)
sample_entries = []

for title, url in sample_links:
    data = extract_entry_data(title, url)
    if data:
        sample_entries.append(data)

# è¾“å‡ºç»“æœé¢„è§ˆ
for entry in sample_entries:
    print(json.dumps(entry, indent=2, ensure_ascii=False))